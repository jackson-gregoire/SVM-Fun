import numpy as np
import scipy as sp
import sklearn as sk
from sklearn import model_selection
from sklearn import decomposition
from sklearn.model_selection import KFold
import sys
np.set_printoptions(threshold=sys.maxsize)
import cvxopt
from cvxopt import matrix, solvers
import matplotlib.pyplot as plt


def svm_dual(file_name, cross_val):
    # Data Formatting
    data = np.loadtxt(file_name, delimiter=",")
    data = sk.preprocessing.scale(data)
    X = np.array(data[:, :data.shape[1] - 1])
    y = np.array(data[:, data.shape[1] - 1]).reshape(-1, 1)
    y = np.where(y == 0, -1, y)
    X_split, X_test, y_split, y_test = model_selection.train_test_split(X, y, test_size=0.2, train_size=0.8)

    # Reduced Trial Data
    test_X = np.array(X_split[:800])
    test_y = np.array(y_split[:800]).reshape(-1, 1)
    test_y = np.where(test_y == 0, -1, test_y)

    # Training SVM via KFold for % OF PROBLEM 2 DATA
    # 0 as last arguement is the linear kernel
    w, b, avg, hyper_c = train_svm(test_X, test_y, cross_val, 'linear', 0)

    # Training SVM via KFold for ALL HOMEWORK PROBLEM 2 DATA
    # w,b = train_svm(X_split,y_split,cross_val,'linear',0)

    # Testing Hold Out Data
    test_accuracy = test_svm(X_test, y_test, w, b)
    print_test_stats(test_accuracy, hyper_c, 0)


def train_svm(X, y, cross_val, kernel_type, gamma):
    C = np.array([10 ** (-4), 10 ** (-3), 10 ** (-2), 0.1, 1, 10, 100, 1000])
    kf = sk.model_selection.KFold(n_splits=cross_val)
    kf_data = kf.split(X)
    opt_w = []
    opt_bs = []
    opt_score = []
    opt_c = []
    average_score = []
    training_std = []
    k_index = 1

    # Might need to switch the for loops (They are currently switched)
    for train_index, test_index in kf_data:
        X_train_fold = X[train_index]
        y_train_fold = y[train_index]
        X_test_fold = X[test_index]
        y_test_fold = y[test_index]
        local_w = []
        model_score = []
        training_score = []
        b_vals = []

        # Iterating through all of the C values on a given fold
        # i.e. C[0], ..., C[n] ---> Fold 1
        for c in C:
            solvers.options['show_progress'] = False
            P, q, G, h, A, b = opt_format(X_train_fold, y_train_fold, c)
            lagrange = cvxopt.solvers.qp(P, q, G, h, A, b)
            a = np.ravel(lagrange['x']).reshape((-1, 1))
            # Each weight vector is associate with the C we're iterating on
            # So taking the best w vector corresponds to taking the best w vector
            w = calc_w(X_train_fold, y_train_fold, a)
            # Once we've iterating through all the C's local_w will contain every
            # weight vector of all the C's.
            local_w = np.append(local_w, w).reshape((-1, X.shape[1]))
            b = calc_b(X_train_fold, y_train_fold, a, c, kernel_type, gamma)
            b_vals = np.append(b_vals, b)
            # Predictions for training data
            predictions = np.sign(predict(X_train_fold, y_train_fold, a, b, kernel_type, gamma))
            # Acc Score for training data
            score = sk.metrics.accuracy_score(y_train_fold, predictions, True)
            # Each training score in the array is associated with a specific C
            training_score = np.append(training_score, score)
            # All of the accuracies up to here seem to be in order, but things after
            # the training data scores don't seem right.
            ##########################################################################
            test_fold_score = test_svm(X_test_fold, y_test_fold, w, b)
            model_score = np.append(model_score, test_fold_score)

        print_training_stats(training_score, model_score, cross_val, k_index)
        k_index += 1
        average_score = np.append(average_score, np.mean(model_score))
        # From all the model scores generated by ALL the C's we take the best
        # (from the validation)
        max_index = np.argmax(model_score)
        # This finds the best model score
        opt_score = np.append(opt_score, model_score[max_index])
        # Gets the corresponding weights for the best score
        opt_w = np.append(opt_w, local_w[max_index]).reshape((-1, X.shape[1]))
        # Gets corresponding b
        opt_bs = np.append(opt_bs, b_vals[max_index])
        opt_c = np.append(opt_c, C[max_index])

    overall_index = np.argmax(opt_score)
    return opt_w[overall_index], opt_bs[overall_index], average_score, opt_c[overall_index]


# Replication stems from something in the predict/kernel function. Could be from
# the linear algebra used.
def predict(X, y, a, b, kernel_type, gamma):
    y_predict = []
    a_t_crossterm = a * y

    if kernel_type == 'linear':
        kern = kernel(X, X, kernel_type, gamma)
        y_x = np.sum(a_t_crossterm * kern, axis=1) + b
        y_predict = np.append(y_predict, y_x)

    if kernel_type == 'rbf':
        index = 0

        for i in X:
            y_x = 0

            for j in X:
                kern = kernel(j, i, kernel_type, gamma)
                y_x += a_t_crossterm[index] * kern

            index += 1
            y_predict = np.append(y_predict, y_x) + b

    return y_predict


def kernel(X, x, kernel, gamma):
    if kernel == 'linear':
        return np.dot(X, np.transpose(X))

    if kernel == 'rbf':
        return np.exp(-gamma * (np.dot((x - X), (x - X))))


def calc_w(X, y, a):
    return np.sum(a * y * X, axis=0).reshape((-1, 1))


def calc_b(X, y, a, c, kernel_type, gamma):
    M_index = np.where((a > 0) & (a < c))[0]
    M = a[M_index]
    S_index = np.where(a > 0)[0]
    S = a[S_index]
    kern = np.dot(X[M_index], np.transpose(X[S_index]))
    elementwise = (a[M_index] * y[M_index] * np.sum(kern, axis=1))

    return (1 / (len(M))) * (np.sum(y[M_index]) - np.sum(elementwise))


def opt_format(X, y, c):
    H = np.matmul(y * X, np.transpose(y * X))
    P = cvxopt.matrix(H)
    q = cvxopt.matrix(-1 * np.ones((X.shape[0])))
    G = cvxopt.matrix(np.vstack((-1 * np.eye(X.shape[0]), np.eye(X.shape[0]))))
    h = cvxopt.matrix(np.hstack((np.zeros(X.shape[0]), c * np.ones(X.shape[0]))))
    A = cvxopt.matrix(y.reshape(1, -1)) * 1.0
    b = cvxopt.matrix(np.zeros(1))

    return P, q, G, h, A, b


def print_training_stats(training_score, model_score, cross_val, idx):
    print("-------------------------------------------------------------------")
    print("Training scores (normalized) for iteration", idx, "of", cross_val, ":")
    print("-------------------------------------------------------------------")
    print(training_score)
    print()
    print("Average training accuracy:", np.mean(training_score))
    print("Standard deviation:", np.std(training_score))
    print("-------------------------------------------------------------------")
    print("Validation scores (normalized) for iteration", idx, "of", cross_val, ":")
    print("-------------------------------------------------------------------")
    print(model_score)
    print()
    print("Averaged validation accuracy: ", np.mean(model_score))
    print("-------------------------------------------------------------------")
    print()


def print_test_stats(test_accuracy, hyper_c, gamma):
    if gamma != 0:
        print()
        print("*******************************************************************")
        print("Optimal hyperparamter Gamma: ", gamma)
        print("Optimal hyperparamter C: ", hyper_c)
        print("Test set accuracy: ", test_accuracy)
        print("*******************************************************************")
        print()
    else:
        print()
        print("*******************************************************************")
        print("Optimal hyperparamter C: ", hyper_c)
        print("Test set accuracy: ", test_accuracy)
        print("*******************************************************************")
        print()


def test_svm(X, y, w, b):
    y_x = []
    y_x = np.append(y_x, np.dot(np.transpose(w), np.transpose(X)) + b)
    score = sk.metrics.accuracy_score(y, np.sign(y_x), True)

    return score


def main():
    # Getting different accuracies each run, why does it change?
    # Are these matrix formulations valid? Can I use the whole matrix instead so I
    # I don't need to use for loops for the y_x and kernels?

    # ENTER FILE PATH AS
    svm_dual("/content/drive/My Drive/Colab Notebooks/hw2_data_2020.csv", 10)


if __name__ == "__main__":
    main()